 old Mvp -> code reuse, need to optimise for resource management , and concurrent requests . 
 Caching (maybe) (i feel cookie and session can be cached , will save 10-12 seconds  .)
 i feel , even course list wont change that frequently for user -> currently taking 30-38 secs to fetch vi playwirght , also leading to multiple browser instnces -> free tier ec2 memory leakage problem happening. 
 Best if i cache this data for along time (MAYBE GIVE HARD REFRESH OPTION TO REMOVE CACHE AND GET NEW ENROLLED COURSES). 
 Need to limit browser instnaces, guesing every browser instne utilising anywhere from 100mb - 500mb , deoedning on task -> main memory leakage prblm . Maybe have a pool of FIXED number of browser instances ppossible , and reuse old instances , and close instances after work ( might optimise a lot ig ).
 If so , then i feel will be best to queue assingnment checking and doc generating requests and have workers pickup job as and when gets free . (maybe two queues , two types of workers (multiple workers rise and do task as and when browser from browser pool is available. )).
 Main -> rather than searhing for unsubmitted assingments for all courses, will give user optio to select (will reduce time and load alot surely .)
 Maybe even will have capex of max 5-6 assingments doc generation per request. (3-4 min earlier reposne time -> 20-30 s maybe)

 Redis free tier 30mb will be more thn enough . Concern will be about i gues , availibility, since worker 
 (assingment checker) will need cookie and session for every requrest , if redis unavailble -> cause problem , requst fail . Maybe add fallback , and store in supa along with redis . Maybe fire and forget supa storage call .
 But problem will be that if redis fails(or no cache ) and then fallbacks to supa , if it was stored earleir , it will be still there , but cookie and session will not work , since they wil  be of the old session created -> moodle wont authenticate further requests.  Need to think about this problem. 
 Maybe if possible, add something like ttl , or expire (if avaible) along with data in supa ,and mayeb a worker external that runs and cleans stale data . Ok , expire is avaible , can use this approach then to invaldiate stored data and remove after a expiry time from supa . 

 I feel all this is fine , need to gather thoughts -> 
 Memory leakage -> Limited browser pool 
 Queueing -> reduce load ,and externally workers and lift and perfom job ( 2 worker : ass checker , ass doc generator).
 cachcing -> will reduce starting bad 30-40 seconds wait to 100-500 ms .
 supa -> fallback in case redis uunavailable or run out of 30mb free tier storage . 
 Also bucket ofc as used last time in mvp for generated doc storage and link to downlaod those. 
lets foooooooo.
------------------------------------------------------------------------------------------------------------- 
 flow of how it goes, user comes, puts their moodle username and password, we check in redis if we have a valid cookie for this username, if yes, move to step 2, if no (redis unavailble), we check supabase first, if still no we use playwright browser instance and store the fresh new cookies in the db and redis with same ttl.

Then we check for courses list of that user in the redis, if not, then in db, if not, we get the enrolled courses through playwright browser instance, and store course list in redis and db with same ttl.

Now after this, flow 2 unlocks where user can select the course they want to check pending assignments for, this goes in a queue, and then using browser pool, these are picked by worker and checks the pending assignment of that subject. Then this data received is stored in only supabase with ttl and flow 3 unlocks.

In this flow, the user gets to see the unsubmitted assignments of the courses selected by them, and then he selects the assignments he wants to generate doc for (max 5), and this goes into a queue, and as and when assignments are generated, the .doc files are uploaded to supabase, and at the end, we return all the files download link to the user to download the assignment. 

-----------------------------------------------------------------------------------------------------

i feel i hv high level clear overview now , will begin . 
-----------------------------------------------------------------------------------------------------
Need to setup initial browser pool , and its corresponfing functions to release , get , del instances.
DOne , maybe need to tweak no of instances as per ec2 limits .
next is need to complete supa client initialistio , and export cleint for rest to use . 
Done with supa client , exported .  Also ,ran sql query for required db tables . 
But will neeed dependent client functions of supa to get json files , delete json files , check json file availinility in supa . 
getjson-> parameter (fileName) (Maybe) , (Will have to store files such tht , getting files with file name is generalised)
DONE .   // ( not tested) // 

Now next , setup redis client simple   , and getter, checker, setter , functions for checking and storing cache .
DOne boiii . 

Next -> setup queue and queue manangers (2 : assingment check queuer , doc gen queuer (will implement this later )).
Now finally starting with ednpoitns , controllers and workers. 

1) f- 1 -> DOne with checking cookie (redis,supa) -> if not present-> playwright -> store in redis,supa with same ttl. 
//now about checking enrolled courses  -> redis cache ? get : (supa ? get : playwright) 
done checking enrolled coursesand caching + storing with same ttl . 

2) f-2 : Now need to get the selected courses list from client, and then need to check all the assingments for that course . 
user selects -> queued -> assingmentSub checker worker picksup one by one  ( will use last mvp code to get ass status -> worker code ) . 
Parallely -> pooling status of job endpoint , maybe (need to get ws for this , since consistently htting server).
(in client need to stop pooling when status: completed / failed)  

fLOW-2 DONE , WILL HAVE TO THINK ABOUT THE POOLING ISSUE LATER . Right now moving to f-3 .
3)
f-3 : Selects assingments, (endpoint should get expoeriments choosen list as array )
done this endpoint , need to set up queue manager  , and build worker for this doc gen ( will use last built mvp code for this worker)
Request received -> queued -> gendoc worker will pickup and complete job . return url of doc in supa bucket to client .




done done done -> boi make simple frontend , and done . (need to consider/limit pooling request problem still).

Problems still existing :- Caching of course experinents , large pooling for job status . 